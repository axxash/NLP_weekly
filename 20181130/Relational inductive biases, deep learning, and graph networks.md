### 论文题目
Relational inductive biases, deep learning, and graph networks

### 作者
    1.Peter W. Battaglia
    2.Jessica B. Hamrick
    3.Victor Bapst

### 摘要
Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning.

### 推荐理由
这篇由DeepMind、Google大脑、MIT、爱丁堡大学27个作者发表的37页关于关系归纳偏置、典型深度学习构件和图网络的综述文章，探讨了如何在深度学习架构中使用关系归纳偏置，有助于学习实体、关系及其组合规则，来有效解决传统“人工构造学习”和“端到端学习”的弊端，以增强学习的可解释性。 对此，一些知名的AI学者也对此做了点评。康纳尔大学数学博士/MIT博士后Seth Stafford说图神经网络(Graph NNs) 可能解决之前Judea Pearl提出的人工智能因果推断问题，贝叶斯网络之父Judea Pearl：要建立真正的人工智能，少不了因果推理。

### 论文地址
[PDF下载](http://cn.arxiv.org/pdf/1806.01261.pdf)
