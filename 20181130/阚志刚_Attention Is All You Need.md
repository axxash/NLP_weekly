## 题目
Attention Is All You Need


## 主要工作
主要序列模型基于包括编码器和解码器的复杂的递归或卷积神经网络。性能最佳的模型还通过注意机制连接编码器和解码器。作者提出了一种新的简单网络架构，Transformer，完全基于注意机制，完全消除了重复和卷积。文章中在点乘注意力机制的基础上，并提出了多头注意力机制。由于注意力机制中没有位置信息，因此在word embadding过程中使用正弦余弦函数进行位置编码。
