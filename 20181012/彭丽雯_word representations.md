## 论文题目
Efficient Estimation of Word Representations in Vector Space
## 作者
Tomas Mikolov
## 发表会议
ICLR 2013
## 摘要
我们提出了两种新颖的模型体系结构，用于计算来自非常大的数据集的单词的连续矢量表示。 在单词相
似性任务中测量这些表示的质量，并且将结果与基于不同类型的神经网络的先前最佳执行技术进行比较。 
我们以低得多的计算成本观察到准确性的大幅提高，即从16亿字数据集中学习高质量字向量需要不到一天
的时间。 此外，我们表明这些向量在我们的测试集上提供了最先进的性能，用于测量句法和语义单词的相似性。
## 论文下载地址
[论文](https://arxiv.org/abs/1301.3781)点击下载
## 推荐理由
这篇论文提出了word2vec的两种基本模型CBOW和skip-gram，并且通过对比传统的利用神经网络学习语言模型的方法，发现本文的方法能够更好地提取出语言的语义和语法信息，
同时在效率方面有很大提升．
