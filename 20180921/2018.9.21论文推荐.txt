(1)杨森: 
推荐论文：Language Modeling with Gated Convolutional Networks
推荐理由：Facebook于2017年提出的基于CNN的语言模型，主要的贡献包括：1.提出了一种新的门控机制取代激活函数，并首次将门控机制应用到CNN中；2.相比与LSTM，收敛速度更快; 

(2)李真真：
推荐论文：Effective Deep Memory Networks for Distant Supervised　Relation Extraction  (IJCAI-17) 
推荐理由：
为了解决关系抽取领域使用远程监督方法的多实例多标签的问题，作者观察到：一个句子的上下文的词对于关系抽取任务的贡献不同；不同的关系存在依赖和隐式的关系表达（如蕴含，冲突等）。因此作者提出一个基于注意力记忆机制的神经网络去学习上述两个信息。在NYT10数据集上的实验结果证明本文提出的模型能有效提高性能。

(3)阚志刚：
推荐论文：Convolutional Neural Network For Sentence Classification
推荐理由：这篇文章比较老了，是2014年的文章。这篇文章的作者用CNN来进行文本分类。在这篇论文中，作者在通过非监督神经语言模型训练的词向量上训练一个只有一个卷积层的CNN。作者开始是保持这些词向量不变仅改变模型的其它参数。尽管调节少量的参数，该简单的模型就在很多基准上达到了非常好的结果，这说明预训练的词向量是“通用的”特征抽取器，可以被应用在很多分类任务上。作者证明了通过细粒度的调节训练的针对特定任务的词向量可以在很多基准上取得非常好的结果。作者最终对架构做了简单的修改，借助多个通道可以同时使用预训练的词向量和特定任务的词向量。这篇文章使用CNN模型在7个任务的4个当中取得目前最好的结果，包括情感分类和问题分类。

(4)彭丽雯：
推荐论文：struc2vec-Learning Node Representations from Structural Identity
推荐理由：这篇论文是发表在KDD2017上的论文，第一作者是里约热内卢联邦大学的Leonardo F. R. Ribeiro。本文提出通过结构识别的方式学习网络中的节点表示。在图表示学习中，节点表示的学习主要依赖于临近性与同构性，前者是指距离越近的节点得到的表示也应该相互靠近，后者是指结构相似的节点得到的表示也应该相互接近。与DeepWalk、node2vec这类通过模仿DFS/BFS来权衡同构性/邻近性不同，struc2vec试图通过直接定量地挖掘图中节点的结构来得到更多保存图中“同构性”的表示。struc2vec定量描述图中节点的结构相似性，同时由考虑“邻域”的大小自然地划分为不同的层次，构造出多层加权图，通过随机游走得到每一节点的上下文信息，最后由Skip-Gram模型对游走序列进行学习，得到节点表示。

